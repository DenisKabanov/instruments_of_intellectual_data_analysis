{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Натренировать нейронную сеть, отличающую классы bicycle, motorcycle, background (всё, что не велосипед и не мотоцикл). (6 баллов)\n",
    "    * Можно использовать претренированную модель, но нужно ее дообучить.\n",
    "    * Не должно быть багов (обратите внимание на дисбаланс классов).\n",
    "2) Провести анализ результатов (confusion матрица, зависимость точности от внешних условий, сравнение моделей, анализ метрик, ...). (1-2 балла в зависимости от полноты анализа)\n",
    "3) Сравнить производительность в разных рантаймах: onnxruntime, tensorrt, tvm, tflite, pytorch-keras, openvino... (0.5 балла за каждый фреймворк)\n",
    "4) Продемонстрировать манипуляцию весами: трансформировать первый слой, чтобы количество входных каналов в первой свертке было не 3, а 1 с минимальной потерей точности. То есть, сетка должна работать на грейскейле. (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройки/Гиперпараметры/Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision # для работы (скачивания, преобразования...) с картинками (датасетом)\n",
    "import matplotlib.pyplot as plt # для вывода графиков/картинок\n",
    "\n",
    "import torch # для работы с тензорами и моделями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка датасета и модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-100 — датасет, состоящий из 60 000 изображений, поделенных на 100 классов. В обучающей выборке присутствуют 50 000 изображений, по 500 сэмплов для каждого класса. Тогда как в тестовой — 10 000 по 100 сэмплов.\n",
    "\n",
    "Каждое изображение имеет размерность (3, 32, 32) ~ (Channels, Height, Width)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы (labels) датасета:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Класс 0: apple\n",
      "Класс 1: aquarium_fish\n",
      "Класс 2: baby\n",
      "Класс 3: bear\n",
      "Класс 4: beaver\n",
      "Класс 5: bed\n",
      "Класс 6: bee\n",
      "Класс 7: beetle\n",
      "Класс 8: bicycle\n",
      "Класс 9: bottle\n",
      "Класс 10: bowl\n",
      "Класс 11: boy\n",
      "Класс 12: bridge\n",
      "Класс 13: bus\n",
      "Класс 14: butterfly\n",
      "Класс 15: camel\n",
      "Класс 16: can\n",
      "Класс 17: castle\n",
      "Класс 18: caterpillar\n",
      "Класс 19: cattle\n",
      "Класс 20: chair\n",
      "Класс 21: chimpanzee\n",
      "Класс 22: clock\n",
      "Класс 23: cloud\n",
      "Класс 24: cockroach\n",
      "Класс 25: couch\n",
      "Класс 26: crab\n",
      "Класс 27: crocodile\n",
      "Класс 28: cup\n",
      "Класс 29: dinosaur\n",
      "Класс 30: dolphin\n",
      "Класс 31: elephant\n",
      "Класс 32: flatfish\n",
      "Класс 33: forest\n",
      "Класс 34: fox\n",
      "Класс 35: girl\n",
      "Класс 36: hamster\n",
      "Класс 37: house\n",
      "Класс 38: kangaroo\n",
      "Класс 39: keyboard\n",
      "Класс 40: lamp\n",
      "Класс 41: lawn_mower\n",
      "Класс 42: leopard\n",
      "Класс 43: lion\n",
      "Класс 44: lizard\n",
      "Класс 45: lobster\n",
      "Класс 46: man\n",
      "Класс 47: maple_tree\n",
      "Класс 48: motorcycle\n",
      "Класс 49: mountain\n",
      "Класс 50: mouse\n",
      "Класс 51: mushroom\n",
      "Класс 52: oak_tree\n",
      "Класс 53: orange\n",
      "Класс 54: orchid\n",
      "Класс 55: otter\n",
      "Класс 56: palm_tree\n",
      "Класс 57: pear\n",
      "Класс 58: pickup_truck\n",
      "Класс 59: pine_tree\n",
      "Класс 60: plain\n",
      "Класс 61: plate\n",
      "Класс 62: poppy\n",
      "Класс 63: porcupine\n",
      "Класс 64: possum\n",
      "Класс 65: rabbit\n",
      "Класс 66: raccoon\n",
      "Класс 67: ray\n",
      "Класс 68: road\n",
      "Класс 69: rocket\n",
      "Класс 70: rose\n",
      "Класс 71: sea\n",
      "Класс 72: seal\n",
      "Класс 73: shark\n",
      "Класс 74: shrew\n",
      "Класс 75: skunk\n",
      "Класс 76: skyscraper\n",
      "Класс 77: snail\n",
      "Класс 78: snake\n",
      "Класс 79: spider\n",
      "Класс 80: squirrel\n",
      "Класс 81: streetcar\n",
      "Класс 82: sunflower\n",
      "Класс 83: sweet_pepper\n",
      "Класс 84: table\n",
      "Класс 85: tank\n",
      "Класс 86: telephone\n",
      "Класс 87: television\n",
      "Класс 88: tiger\n",
      "Класс 89: tractor\n",
      "Класс 90: train\n",
      "Класс 91: trout\n",
      "Класс 92: tulip\n",
      "Класс 93: turtle\n",
      "Класс 94: wardrobe\n",
      "Класс 95: whale\n",
      "Класс 96: willow_tree\n",
      "Класс 97: wolf\n",
      "Класс 98: woman\n",
      "Класс 99: worm\n"
     ]
    }
   ],
   "source": [
    "classes = [\"apple\",  \"aquarium_fish\", \"baby\", \"bear\", \"beaver\", \"bed\", \"bee\", \"beetle\", \"bicycle\", \"bottle\", \"bowl\", \"boy\", \"bridge\", \"bus\", \"butterfly\", \"camel\", \"can\", \"castle\", \"caterpillar\", \"cattle\", \"chair\", \"chimpanzee\", \"clock\", \"cloud\", \"cockroach\", \"couch\", \"crab\", \"crocodile\", \"cup\", \"dinosaur\", \"dolphin\", \"elephant\", \"flatfish\", \"forest\", \"fox\", \"girl\", \"hamster\", \"house\", \"kangaroo\", \"keyboard\", \"lamp\", \"lawn_mower\", \"leopard\", \"lion\", \"lizard\", \"lobster\", \"man\", \"maple_tree\", \"motorcycle\", \"mountain\", \"mouse\", \"mushroom\", \"oak_tree\", \"orange\", \"orchid\", \"otter\", \"palm_tree\", \"pear\", \"pickup_truck\", \"pine_tree\", \"plain\", \"plate\", \"poppy\", \"porcupine\", \"possum\", \"rabbit\", \"raccoon\", \"ray\", \"road\", \"rocket\", \"rose\", \"sea\", \"seal\", \"shark\", \"shrew\", \"skunk\", \"skyscraper\", \"snail\", \"snake\", \"spider\", \"squirrel\", \"streetcar\", \"sunflower\", \"sweet_pepper\", \"table\", \"tank\", \"telephone\", \"television\", \"tiger\", \"tractor\", \"train\", \"trout\", \"tulip\", \"turtle\", \"wardrobe\", \"whale\", \"willow_tree\", \"wolf\", \"woman\", \"worm\"]\n",
    "for i in range (len(classes)):\n",
    "    print(f\"Класс {i}: {classes[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Нужные нам классы находятся под индексами 8 (bicycle) и 48 (motorcycle), всё остальное будем считать за \"background\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# преобразования над датасетом\n",
    "transforms = torchvision.transforms.Compose([ # Compose объединяет несколько преобразований вместе, чтобы они выполнялись \"последовательно\"\n",
    "                                             torchvision.transforms.ToTensor(), # преобразование PIL изображения (или ndarray формата (Height x Width x Channels)) в tensor (типа float со значениями в области [0.0, 1.0], если такая трансформация поддерживается (см описание ToTensor))\n",
    "                                             torchvision.transforms.Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761)) # нормализация каналов (в датасете три канала) к указанным среднему значению и стандартному отклонению (цифры подобраны под датасет)\n",
    "])\n",
    "\n",
    "# датасет для обучения\n",
    "data_train = torchvision.datasets.CIFAR100(root=\"./data\", # путь, откуда брать/куда сохранять датасет\n",
    "                                           train=True, # скачиание обучающей части датасета\n",
    "                                           download=True, # скачивать ли датасет, если его нет в root пути\n",
    "                                        #    transform=transforms # функция, принимающая на вход PIL Image и преобразовывающая его\n",
    "                                          )\n",
    "\n",
    "# загрузчик данных для обучения\n",
    "loader_train = torch.utils.data.DataLoader(dataset=data_train, # указание датасета для DataLoader\n",
    "                                           batch_size=20, # размер батчка (число сэмплов, что будет возвращать DataLoader за раз) (градиент усредняется по батчу, ускоряется обработка датасета, но слегка замедляется обработка сэмпла)\n",
    "                                           num_workers=5, # число используемых ядер процессора для ускорения обработки данных\n",
    "                                           pin_memory=True # нужно ли заранее аллоцировать память под объект на GPU (лучше так, чем возвращать CUDA tensors при multi-process loading)\n",
    "                                           )\n",
    "\n",
    "# аналогично для тестирования\n",
    "data_test = torchvision.datasets.CIFAR100(root=\"./data\", # путь, откуда брать/куда сохранять датасет\n",
    "                                          train=False, # скачиание обучающей части датасета\n",
    "                                          download=True, # скачивать ли датасет, если его нет в root пути\n",
    "                                        #   transform=transforms # функция, принимающая на вход PIL Image и преобразовывающая его\n",
    "                                         )\n",
    "\n",
    "loader_test = torch.utils.data.DataLoader(dataset=data_test, # указание датасета для DataLoader\n",
    "                                          batch_size=20, # размер батчка (число сэмплов, что будет возвращать DataLoader за раз) (градиент усредняется по батчу, ускоряется обработка датасета, но слегка замедляется обработка сэмпла)\n",
    "                                          num_workers=5, # число используемых ядер процессора для ускорения обработки данных\n",
    "                                          pin_memory=True # нужно ли заранее аллоцировать память под объект на GPU (лучше так, чем возвращать CUDA tensors при multi-process loading)\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = None\n",
    "for sample, label in data_train:\n",
    "    if label == 8:\n",
    "        image = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAW7klEQVR4nO3deZRV1ZUG8G+HMYIIhIIUQ1ESie0UQB8ukiZOaVHpRMQVWZhO2sQBY0t3cCXd0ppEiMmKMVE00UCKwSmJigorJK0RAkY0NEghMgVFJMU8lEgxBkzB7j/uZXVB7t716g33FZzvt1atenV2nXs3l9r1Xt3zzjmiqiCik99HSp0AEaWDxU4UCBY7USBY7ESBYLETBYLFThSIlvl0FpErATwMoAWAKap6n/f9Xbp00crKynxOSSe4ul17zFjHTh1SzKT5OGK0e8/E+7AvsX1bzTbUvV8nSbGci11EWgB4FMDlADYBWCwis1T1z1afyspKVFdX53pKOgnMfP73Zmz4F69MMZPm44DRforT509YkNh+U+ZGs08+L+MvBLBWVdep6ocAngEwLI/jEVER5VPsPQBsbPD1priNiJqhot+gE5FRIlItItW1tbXFPh0RGfIp9s0AejX4umfcdgxVrVLVjKpmysrK8jgdEeUjn2JfDKCviJwuIq0BjAQwqzBpEVGh5Xw3XlXrRWQ0gJcRDb1NU9VVBcuMTnDJQ2zXXneV2eM7Y6vM2Pd+eEveGTVXTy3+UWL7uvUvmX0WLnotsX3zJmsgL89xdlV9EcCL+RyDiNLBd9ARBYLFThQIFjtRIFjsRIFgsRMFIq+78US23zW5x8vTnjVjJ/rQ2y4ndsXAf0psn97WHnqbf6cxxOaciM/sRIFgsRMFgsVOFAgWO1EgWOxEgeDdeMrdFvuO+8yvfqPJh6veMdeMPTz+B2bskltuM2P9unduch7FUI+3zdgL65L/bX989VX7gAeNdmc3Nz6zEwWCxU4UCBY7USBY7ESBYLETBYLFThQIDr0V2y/H27HZb5ihmdvamLHhs2fkk1GT3Hn118zY0t8+bsZy2ffHXj0NGDPu22bswmUbzdiiGZNyyMQ27yF7H5Tpk+31Vq/478Fm7N2DycNyO99pZSfS9m/J7YkbP0X4zE4UCBY7USBY7ESBYLETBYLFThQIFjtRIETVmSbTWGeRGgB7ARwGUK+qGe/7M5mMVlfnMijTzK1Ya8d++k071vIDO7Z5hxmat6/cjF0274/2MQ3ScqAdPFzY/y87c2BrQc8UeWRe8s/37ZfafXa9lrwdEwD0vmisGdvr5HGRE+t7c/Kw3KEzrjT7tOuRfMQXvnsLate9nTgAV4hx9ktV9f0CHIeIiogv44kCkW+xK4DZIrJEREYVIiEiKo58X8YPVtXNItIVwBwReVtV5zf8hviXwCgAqKioyPN0RJSrvJ7ZVXVz/HkHgJkALkz4nipVzahqpqysLJ/TEVEeci52EWknIqcefQxgCICVhUqMiAorn5fx3QDMFJGjx/m1qv6+IFmdaM47wwk6r2Zm2LOk8HE71HX9GjP20oibE9vXXHaHfcACD695ijG85hl9WfI0sIkt7D7vHrZjZznnstaABIAtTuxb/ZKH2Np86W6zzwajcn//QHuzT87FrqrrAPTLtT8RpYtDb0SBYLETBYLFThQIFjtRIFjsRIHggpPF9ugUM7RsylQz1t2e9AYnhDueSz7mO8/VOL3Cs8oZXvPsdGKbnFgnJ/bk5ImJ7QPPtKfmdb38M4nt4gwp8pmdKBAsdqJAsNiJAsFiJwoEi50oEHmtQddUJ+0adEVwYOjZZuyUUf9mxu6ctT+x/f7H7LXTclWG88zYkpnJ2y5VDP/HgudxIvAmd9fmdERra6h6qB5JnP3DZ3aiQLDYiQLBYicKBIudKBAsdqJAsNiJAsGhtxI64MS2rHvDjJ3R5+8W8W1UvFZgQXk/O/Me+U1i++f+/ZqC50HHUlUOvRGFjMVOFAgWO1EgWOxEgWCxEwWCxU4UiEbXoBORaQA+D2CHqp4bt3UG8CyASgA1AEao6q7ipZlsthMb6MS89cAKbciU5PXFAGDOj39md3zPngu1v96O7c5xbTXL7Z+9Lqd+ry9YUthEKG/ZPLM/DuD4zajGApirqn0BzI2/JqJmrNFij/db/+C45mEAnogfPwHgmsKmRUSFluvf7N1U9eiGnNsQ7ehKRM1Y3jfoNHrPpPm+SREZJSLVIlJdW5vbmhxElL9ci327iJQDQPzZ3LdAVatUNaOqmbIyb3EeIiqmXIt9FoAb4sc3AEie9UBEzUY2Q29PA7gEQBcR2QTgHgD3AZguIjcBWA9gRDGTXGa0P/TLF8w+3buVm7EpxtY5uXpuwytmbM699uKQ2JDb+b7wyGgzNnf0w7kd1DDo6n8xY7Vz7Jl5Tz39ZEHzoPw1Wuyqer0R+lyBcyGiIuI76IgCwWInCgSLnSgQLHaiQLDYiQLR6N34tMx3Vl+8dGTyUNO9U24x+zw2wR4W6jzRjn0wY4wZe+7A2sT270y4z+yD9j3sGDY7MVvF/r840RaJrVsem2f2eP1P9gy16y62F7dcUjXNjK3FejNGpcFndqJAsNiJAsFiJwoEi50oECx2okCw2IkC0WyG3i7u0NOMdbrl+CXwIlvWbzT7rL3vWeds9Wbk5lfambGpI0cZEe93ZgcnlptrL7u0yX3Kv2r3uW6Ec7x29v9LH2focLLRbg+WUrHxmZ0oECx2okCw2IkCwWInCgSLnSgQzeZu/EeGnGPGdk2amtj+qNGej6mT37SDh4z23UecI9bllMdHhtuxdZuP37OjAW/fK8u99lp+3mSdhU6vPkb7y06fSU5sphOj7PCZnSgQLHaiQLDYiQLBYicKBIudKBAsdqJAZLP90zQAnwewQ1XPjdvGIZrTcHRb1rtU9cXGjrUPwHwjdqTenoACK7S/sTPmYN9eO7a7sKdqfVUXM/bhzPfN2KyOC8zYN64xAoedRO672QzZEaDQA59fdGIXOTHrZ4qOlc0z++MAkqadTVDV/vFHo4VORKXVaLGr6nwAzrs4iOhEkM/f7KNFZLmITBORTgXLiIiKItdinwjgEwD6A9gK4AHrG0VklIhUi0h1XW2t9W1EVGQ5FbuqblfVw6p6BNGiJOZOAqpapaoZVc10LCvLNU8iylNOxS4i5Q2+HA5gZWHSIaJiyWbo7WkAlwDoIiKbANwD4BIR6Q9AAdQAuDWbk22prcX3J01MjLXuaI8NtRw6OLH9wHOvZ3Pav9Pz6/9hxn4+8W4zdvUF/5wcqLNzv/zG5K2rAGDYkH5mbPcdq8zYmMv/1YyZJv/ODC1xZuYVfl6h7fkc+12VQ5+XcjzXiazRYlfV6xOa0/wZIKIC4DvoiALBYicKBIudKBAsdqJAsNiJApHqgpNdyg7hxq/XJMYuufoMs9/OnTsS2x+sX2Sf7MW/maHTKu3pctsP2O/ym/zKlMT2Dau2mn0e+7E9yPO7u280Y61xgRnLyQRrQyagzccGmLGFd9xpxja06WzGqpfXJLbv3md2wS9mWttr+VY7sUxORzw58ZmdKBAsdqJAsNiJAsFiJwoEi50oECx2okCIqqZ3sg6iGGQEncUcK7+d3H7/F4aYfX7y/Gwz1tYZcOzerbcZO7TvlMT2pQv2mH1qquy90vpda10MINPPnhE3deISM9Zz08bE9p/3vNzs06a3Pcz39EFrgzvg8ZfGmrHmwrqKy1LNIl2qKkntfGYnCgSLnSgQLHaiQLDYiQLBYicKRKp34zucIzrwmeTYzjq737WfTW73dn96aLwdO+00O9bV3pEJq6yb4M5IQvmZduysHvbv2nN7dzBjLdu3MWOH9rVNbL+zo70WXsWn/tOM0YmHd+OJAsdiJwoEi50oECx2okCw2IkCwWInCkQ22z/1AvAkgG6ItnuqUtWHRaQzgGcBVCLaAmqEqu7yjvXJj7bH3POSJ128jRqz301z1ie2L5hvn+sn99qxAfioHXQuyYzr9ya279xuH22pk+PiVUfM2BVD6uxY17PM2AokD731wmfMPqeeZh9v725vhbdcdHRidTkd0V69EFib0xFPTtk8s9cD+Kaqng1gEIDbReRsAGMBzFXVvgDmxl8TUTPVaLGr6lZVfTN+vBfRYp49AAwD8ET8bU8AuKZIORJRATTpb3YRqQQwAMAiAN1U9egaytsQvcwnomYq62IXkfYAXgAwRlWPWa1Bo/fcJr7vVkRGiUi1iFTX1tpruRNRcWVV7CLSClGh/0pVZ8TN20WkPI6XA0jcyUFVq1Q1o6qZsrJWhciZiHLQaLGLiCDaj321qj7YIDQLwA3x4xsA/Kbw6RFRoTQ6601EBgN4DcAKAEfHiu5C9Hf7dAAVANYjGnr7wDvW2RnRp6qTY22cIZkLxtcltn84zjubw54Ahh/8zI6NMH439sH5Zp96ZyhvvzNvrxNOtxNxHEB9Yvsp+B+zz58WJ2+vBQCP3PM9M/bMS49mn1gRleM8M7YVK1LMpHmwZr01Os6uqq8DSOwM4HP5JEVE6eE76IgCwWInCgSLnSgQLHaiQLDYiQKR6oKTAzKirxpDb4edmWj70Cux/WlnTtP4h+wZZQdmmCFc9bgd+1Kf5PYNdhcMdmL9nXcYd0B3M7YSS83YufiqEXnMycQm0tOJ2ltbpenLw281Y7+c+YsUM2keuOAkUeBY7ESBYLETBYLFThQIFjtRIFjsRIFIdejtgozo/xpDb63dnoOM9nOcPoed2F/MyBFnJtqTSE7+kXXOqZypRtdX2DHrXwwAh5zYecbv7zK8YfZZdOBNO492o5yzNQ9nONdxrTcuepLi0BtR4FjsRIFgsRMFgsVOFAgWO1EgUr0b3zUjOsK4G+/dfbamhGScPh3Q24m2cWJdzcgebExsfxXJ21MBwGLnTD2c2EEnNt1Z6W/hr5Pbv3a13ee2CnsS0oZJyZOQAGDkbWvM2IdGuzd+ssX5b6l3hiCSN+XynerEcjlec8K78USBY7ETBYLFThQIFjtRIFjsRIFgsRMFIpvtn3oBeBLRlswKoEpVHxaRcQBuAVAbf+tdqvqid6xT+ot+cl5yrKKz3c8aevO2o8l1/+i+TqwcFxuRdk6v5OE6ANiFGjO20BkAGnqjczpr+Gq508cZpfyBcyFff8iOfW14x8T2tgf3JLYDwIYzW5ixl6fbOwD/doudR7nRfrp9Kix05lDZKxs2Hzlv/wSgHsA3VfVNETkVwBIRmRPHJqjqTwqVJBEVTzZ7vW0FsDV+vFdEVsN/PwgRNUNN+ptdRCoBDEC0gysAjBaR5SIyTUQ6FTo5IiqcrItdRNoDeAHAGFXdA2AigE8A6I/omf8Bo98oEakWker6nfknTES5yarYRaQVokL/larOAABV3a6qh1X1CIDJAC5M6quqVaqaUdVMy48VKm0iaqpGi11EBMBUAKtV9cEG7Q1vdA4HsLLw6RFRoWQz9DYYwGsAVuD/Rx7uAnA9opfwCqAGwK3xzTxT74zoXcast91OP2s0yVuLbak17QpA9RI7NvrTdmyA0e4tc3aeE+vnDh7aU9uuXWNv/9T3k8nt94+3z9TpNDt2tzPMd+gdO3ZwWXJ7+312n/8aM9SMPTDFHtWdMcY+ZoVxK3l/W7tPvXPbeqG9XB922aFU5Tz0pqqvA0jq7I6pE1HzwnfQEQWCxU4UCBY7USBY7ESBYLETBSKbiTAFUw9guxGzZrYBwFlGu71RE7DGmdV01pl2zDvmH4x2Z/chOGm4Z1vrvG3hWmN4DbBn7X3pHruPN+zpTCjDFQO7mLF1A99PbK9wl3q0t+WqGGpPv+vzpL1IaJtDyaPB+5GcHwC0bWfn2Ke7PRtxiXexmgE+sxMFgsVOFAgWO1EgWOxEgWCxEwWCxU4UiFSH3v4KYLUR84Z/3jLavWUeWzpjXoOcxS3fdY5pdfMuovXvBYC3sNCMrXD6eeqNdu9aebMHvV3x9jnDV9ZEutXOQppLnavV0hmbbXmONaALrJ6V3L7TulAA9jg5bt1h92vu+MxOFAgWO1EgWOxEgWCxEwWCxU4UCBY7USDSnfVWD+w01lFc7SxEeNCYHLZjm92nq7Og4Duz7RhW2aGR05PbFzorTrZ1rvDBg04eznjYgjudfsbksLIr7C6DLnNizjClx5oJaA82Amuc2GFn/7UN9uQ7WFsVHHL2MNjZ3knEm8bo5Ngc8JmdKBAsdqJAsNiJAsFiJwoEi50oENls/9QWwHxEcyJaAnheVe8RkdMBPAPgYwCWAPiKqjqbLgHSXRS3GkHvzrS1IeRjTh97boQ9SwMAnDvTuNhod+78t3YO19fZ6LLi43bspZ86B51ktF/u9HHOZV57AHDW8ut5TnL7pvfsPq3tZebwoTNx5Uzn/3r/D43AOrvPJjsEOOv/ucMJBXbOhOT29x4A/roxefunbJ7ZDwG4TFX7Idrb7UoRGQTgRwAmqOoZiLa5uimHnIkoJY0Wu0aOjoK3ij8U0XPg83H7EwCuKUaCRFQY2e7P3kJE3gKwA8AcAO8BqFPVoy+uNgEw9sskouYgq2JX1cOq2h9ATwAXAviHbE8gIqNEpFpEqnEgtySJKH9NuhuvqnUAXgHwaQAdReTom0F7Aths9KlS1YyqZnBKPqkSUT4aLXYRKRORjvHjjyK6r7saUdF/Mf62GwD8pkg5ElEBZDP09ilEN+BaIPrlMF1VvycifRANvXUGsBTAl1XVW84MIuKfzGINd+Q61PEVO3TRODs2f3Jye+sL7D719jJtGGYN5QHo7gx5rXEmDVUvT27fVWP3wXwntsiJOZNr8Amj3VvUzhsudf7NWODEjOvhbUJlr0AH4LNO7DWvYw762KHKKcntW74OHHoneeit0VlvqrocwICE9nWI/n4nohMA30FHFAgWO1EgWOxEgWCxEwWCxU4UiEaH3gp6MpFaAOvjL7sAzv5B6WEex2IexzrR8uitqmVJgVSL/ZgTi1SraqYkJ2cezCPAPPgynigQLHaiQJSy2KtKeO6GmMexmMexTpo8SvY3OxGliy/jiQJRkmIXkStF5B0RWSsiY0uRQ5xHjYisEJG3RKQ6xfNOE5EdIrKyQVtnEZkjIu/GnzuVKI9xIrI5viZvicjQFPLoJSKviMifRWSViHwjbk/1mjh5pHpNRKStiLwhIsviPMbH7aeLyKK4bp4VEW8907+nqql+IJoq+x6iCXytASwDcHbaecS51ADoUoLzXgTgfAArG7TdD2Bs/HgsgB+VKI9xAL6V8vUoB3B+/PhURJOXz077mjh5pHpNAAiA9vHjVogmGg8CMB3AyLh9EoDbmnLcUjyzXwhgraqu02jp6WcADCtBHiWjqvMBHL/F5TBE6wYAKS3gaeSROlXdqqpvxo/3IlocpQdSviZOHqnSSMEXeS1FsfcAsLHB16VcrFIBzBaRJSIyqkQ5HNVNVbfGj7fB3I81FaNFZHn8Mr/of040JCKViNZPWIQSXpPj8gBSvibFWOQ19Bt0g1X1fABXAbhdRC4qdUJA9Jsd0S+iUpiIaJ2Z/gC2AnggrROLSHsALwAYo6p7GsbSvCYJeaR+TTSPRV4tpSj2zQB6NfjaXKyy2FR1c/x5B4CZKO3KO9tFpBwA4s87SpGEqm6Pf9COAJiMlK6JiLRCVGC/UtUZcXPq1yQpj1Jdk/jcdWjiIq+WUhT7YgB94zuLrQGMBDAr7SREpJ2InHr0MYAhAFb6vYpqFqKFO4ESLuB5tLhiw5HCNRERATAVwGpVfbBBKNVrYuWR9jUp2iKvad1hPO5u41BEdzrfA3B3iXLog2gkYBmAVWnmAeBpRC8H/4bob6+bEO2qNhfAuwD+AKBzifJ4CsAKREs1zgJQnkIegxG9RF8O4K34Y2ja18TJI9VrAuBTiBZxXY7oF8t3G/zMvgFgLYDnALRpynH5DjqiQIR+g44oGCx2okCw2IkCwWInCgSLnSgQLHaiQLDYiQLBYicKxP8ByuPz4I9Ehh8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_train[0][0].permute(1, 2, 0)) # построение изображения\n",
    "# .permute(1, 2, 0) меняет местами размерности, на первое место выходит Height, второе — Width, третье — Channels, так как shape(3, 32, 32) ~ (Channels, Height, Width) не воспринимается\n",
    "# операция схожа с reshape, но permute просто меняет местами индексы, гарантируя, что обращение с соответствующей перестановкой индексов вернёт тот же элемент (что был бы без permute и перестановки индексов)\n",
    "\n",
    "plt.show() # вывод изображения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = timm.create_model(\"hf_hub:edadaltocg/resnet50_cifar100\", pretrained=True) # shape mismatch conv1.weight: copying a param with shape torch.Size([64, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 3, 7, 7])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = timm.create_model(\"hf_hub:daveni/upside_down_classifier\", pretrained=True) # KeyError: 'architecture'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTFeatureExtractor, ViTModel, ViTForImageClassification, ViTImageProcessor\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# image = data_train[0][0] # корова\n",
    "\n",
    "image = None\n",
    "for sample, label in data_train:\n",
    "    if label == 8:\n",
    "        image = sample\n",
    "\n",
    "# feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "feature_extractor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "# model = ViTModel.from_pretrained('edumunozsala/vit_base-224-in21k-ft-cifar100')\n",
    "model = ViTForImageClassification.from_pretrained('edumunozsala/vit_base-224-in21k-ft-cifar100')\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "outputs = model(**inputs)\n",
    "# last_hidden_states = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(outputs.logits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Fine-tuning нейронной сети под задачу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вариант решения проблемы дисбаланса классов — увеличим вес нужных классов при подсчёте loss функции, чтобы ошибка в них сильнее отзывалась в модели. Например — увеличим их вес в 20 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., 20.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1., 20.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         1.,  1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_weights = torch.ones(size=(100,), dtype=dtype) # вектор с весами для \n",
    "loss_weights[8] = 20.0\n",
    "loss_weights[48] = 20.0\n",
    "loss_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss(weight=loss_weights) # создаём функцию для подсчёта loss с указанием \"особых\" весов классов\n",
    "# loss - кросс-энтропия (перекрёстная энтропия)\n",
    "# CrossEntropyLoss на вход ожидает вероятность класса для всех k классов\n",
    "# то есть массив с вероятностями для каждой из четырёх категорий новостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Сравнение производительности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Манипуляция с весами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
