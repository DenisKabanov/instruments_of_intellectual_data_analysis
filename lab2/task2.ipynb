{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решить задачу классификации рукописных цифр на датасете mnist https://www.kaggle.com/datasets/hojjatk/mnist-dataset. Правила следующие:\n",
    "- нужно представить решение в виде нейронной сети, написанной на numpy, и обученной с помощью алгоритма градиентного спуска;\n",
    "- нейронная сеть должна состоять из двух линейных слоев, активаций relu и softmax, и mse лосса;\n",
    "- нельзя пользоваться автоградиентом (pytorch, numpy). Градиенты должны считаться вручную по алгоритму обратного распространения ошибки, используя аналитические формулы производных;\n",
    "- решение считается валидным, если оно достигает аккураси больше 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройки/Гиперпараметры/Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # для вывода графиков/картинок\n",
    "import numpy as np # для работы с матрицами\n",
    "\n",
    "import torchvision # для работы с картинками (преобразований)\n",
    "import torch # для создания модели\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = -1 # номер девайса\n",
    "device = 'cpu' if device_id == -1 else f'cuda:{device_id}' # если номер девайса >=0 - используем GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# преобразования над датасетом\n",
    "transforms = torchvision.transforms.Compose([ # Compose объединяет несколько преобразований вместе, чтобы они выполнялись \"последовательно\"\n",
    "    torchvision.transforms.ToTensor(), # преобразование PIL изображения (или ndarray формата (Height x Width x Channels)) в tensor (типа float со значениями в области [0.0, 1.0], если такая трансформация поддерживается (см описание ToTensor))\n",
    "    torchvision.transforms.Normalize(mean=(0.1307,), std=(0.3081,)) # нормализация каналов (в датасете всего один канал) к указанным среднему значению и стандартному отклонению (цифры подобраны под датасет)\n",
    "])\n",
    "\n",
    "# датасет\n",
    "data_train = torchvision.datasets.MNIST(root=\"./data\", # путь, откуда брать/куда сохранять датасет\n",
    "                                        train=True, # скачиание обучающей части датасета\n",
    "                                        download=True, # скачивать ли датасет, если его нет в root пути\n",
    "                                        transform=transforms # функция, принимающая на вход PIL Image и преобразовывающая его\n",
    "                                       )\n",
    "\n",
    "# загрузчик данных для обучения\n",
    "train_loader = torch.utils.data.DataLoader(dataset=data_train, # указание датасета для DataLoader\n",
    "                                           batch_size=10, # размер батчка (число сэмплов, что будет возвращать DataLoader за раз) (градиент усредняется по батчу, ускоряется обработка датасета, но слегка замедляется обработка сэмпла)\n",
    "                                           num_workers=5, # число используемых ядер процессора для ускорения обработки данных\n",
    "                                           pin_memory=True # нужно ли заранее аллоцировать память под объект на GPU (лучше так, чем возвращать CUDA tensors при multi-process loading)\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
       "           )"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train # данные о датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.3860, -0.1951,\n",
       "          -0.1951, -0.1951,  1.1795,  1.3068,  1.8032, -0.0933,  1.6887,\n",
       "           2.8215,  2.7197,  1.1923, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.0424,  0.0340,  0.7722,  1.5359,  1.7396,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960,  2.4396,  1.7650,  2.7960,\n",
       "           2.6560,  2.0578,  0.3904, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.1995,  2.6051,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.7706,  0.7595,  0.6195,  0.6195,\n",
       "           0.2886,  0.0722, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.1951,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.7960,\n",
       "           2.0960,  1.8923,  2.7197,  2.6433, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242,  0.5940,  1.5614,  0.9377,  2.7960,  2.7960,  2.1851,\n",
       "          -0.2842, -0.4242,  0.1231,  1.5359, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.2460, -0.4115,  1.5359,  2.7960,  0.7213,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242,  1.3450,  2.7960,  1.9942,\n",
       "          -0.3988, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.2842,  1.9942,  2.7960,\n",
       "           0.4668, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0213,  2.6433,\n",
       "           2.4396,  1.6123,  0.9504, -0.4115, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.6068,\n",
       "           2.6306,  2.7960,  2.7960,  1.0904, -0.1060, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.1486,  1.9432,  2.7960,  2.7960,  1.4850, -0.0806, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.2206,  0.7595,  2.7833,  2.7960,  1.9560, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242,  2.7451,  2.7960,  2.7451,  0.3904,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "           0.1613,  1.2305,  1.9051,  2.7960,  2.7960,  2.2105, -0.3988,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,  0.0722,  1.4596,\n",
       "           2.4906,  2.7960,  2.7960,  2.7960,  2.7578,  1.8923, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.1187,  1.0268,  2.3887,  2.7960,\n",
       "           2.7960,  2.7960,  2.7960,  2.1342,  0.5686, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.1315,  0.4159,  2.2869,  2.7960,  2.7960,  2.7960,\n",
       "           2.7960,  2.0960,  0.6068, -0.3988, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.1951,\n",
       "           1.7523,  2.3633,  2.7960,  2.7960,  2.7960,  2.7960,  2.0578,\n",
       "           0.5940, -0.3097, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242,  0.2758,  1.7650,  2.4524,\n",
       "           2.7960,  2.7960,  2.7960,  2.7960,  2.6815,  1.2686, -0.2842,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242,  1.3068,  2.7960,  2.7960,\n",
       "           2.7960,  2.2742,  1.2941,  1.2559, -0.2206, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242],\n",
       "         [-0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242,\n",
       "          -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242, -0.4242]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][0] # первое \"изображение\" датасета после применения трансформаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[0][1] # класс (target) первого изображения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data_train[0][0].reshape((28, 28, 1)), cmap='gray') # построение изображения\n",
    "# .reshape((28, 28, 1)), так как shape(1, 28, 28) ~ (Channels, Height, Width) не воспринимается\n",
    "# cmap='gray' так как изображение одноканальное, то есть чёрно-белое\n",
    "plt.show() # вывод изображения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "ReLU(x) =  \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0 & if & x \\leq 0 \\\\\n",
    "      x & if & x > 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "\\dfrac{dReLU(x)}{dx} =  \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      0 & if & x \\leq 0 \\\\\n",
    "      1 & if & x > 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"pics/ReLU.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Конструктор ReLU функции.\n",
    "        \"\"\"\n",
    "        self.prev_input = None # вход с предыдущего слоя\n",
    "        # print(\"constructed\")\n",
    "\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray: # numpy.array — это просто удобная функция для создания numpy.ndarray\n",
    "        \"\"\"\n",
    "        Функция активации ReLU, если значение в X меньше или равно нулю - оно становится нулём, иначе — остаётся прежним.\\n\n",
    "        Parameters:\n",
    "            * x: данные в виде массива размера (batch_size, features)\\n\n",
    "        Returns:\n",
    "            * np.ndarray: преобразованный x согласно работе функции активации\n",
    "        \"\"\"\n",
    "        self.prev_input = x.copy() # запоминаем вход с предыдущего шага\n",
    "        x[x<0] = 0.0 # заменяем все значения в x, что меньше нуля на ноль\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def backward(self, grad):\n",
    "        grad[self.prev_input < 0] = 0 # зануляем градиент там, где вход был меньше нуля\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Softmax(x_i) = \\dfrac{e^{x_i}}{\\sum_{j}e^{x_j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Конструктор Softmax функции.\n",
    "        \"\"\"\n",
    "        # print(\"constructed\")\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция Softmax, пересчитывающая для всех элементов массива x значение e^x_i/summ(e^x_i).\\n\n",
    "        Parameters:\n",
    "            * x: данные в виде массива размерности (batch_size, class_count) ~ (размер батча, число классов)\\n\n",
    "        Returns:\n",
    "            * np.ndarray: преобразованный X согласно формуле Softmax\n",
    "        \"\"\"\n",
    "        e = np.exp(x) # считаем экспоненту от всех элементов X (каждый элемент в X идёт как степень e)\n",
    "        for batch in range(e.shape[0]): # идём по батчам\n",
    "            e[batch] = e[batch] / e[batch].sum() # каждый элемент (экспоненту) в батче делим на сумму экспонент этого батча\n",
    "        return e # возвращаем результат Softmax\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        return grad # просто возвращаем полученный градиент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Linear layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y = xW^T + b\n",
    "$$\n",
    "* x - вход размера (batch_size, in_features)\n",
    "* W - вектора-строка весов, поэтому для умножения её транспонируют, получая вектор-столбец (in_features, out_features)\n",
    "* b - вектор-строка для смещения размера (out_features)\n",
    "* y - выход размера (batch_size, out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear: # линейный слой без смещения (bias)\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \"\"\"\n",
    "        Конструктор линейного слоя.\n",
    "        \"\"\"\n",
    "        # self.w = np.random.randn(28*28, 196)\n",
    "        # self.bias = np.random.randn(196)\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        self.prev_input = None # вход с предыдущего слоя\n",
    "        self.w = np.random.randn(in_features, out_features)\n",
    "        self.bias = np.random.randn(out_features) # смещение как вектор-строка\n",
    "        # self.w = np.random.randn(out_features, in_feature)\n",
    "        # self.bias = np.random.randn(out_features) # смещение как вектор-строка\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Функция, применяющая веса и смещение к входным данным.\\n\n",
    "        \"\"\"\n",
    "        self.prev_input = x.copy() # запоминаем вход с предыдущего шага\n",
    "        #========== v1\n",
    "        # res = np.matmul(x, np.transpose(self.w)) # умножаем вход на веса\n",
    "        #========== v2\n",
    "        # res = np.matmul(self.w, X) # умножаем вход на веса\n",
    "        #========== v3*\n",
    "        res = np.matmul(x, self.w) # умножаем вход на веса (batch_size, in_features)x(in_features, out_features)=(batch_size, out_features)\n",
    "        #========== v3.1\n",
    "        # res = np.zeros(shape=(x.shape[0], self.out_features))\n",
    "        # for batch in range(x.shape[0]):\n",
    "        #     res[batch] = np.matmul(x[batch], w)\n",
    "        #========== v3.2\n",
    "        # res = np.zeros(shape=(x.shape[0], self.out_features))\n",
    "        # for batch_id, batch in enumerate(x):\n",
    "        #     res[batch_id] = np.matmul(batch, w)\n",
    "        #==========\n",
    "\n",
    "        #========== v1*\n",
    "        # res = np.add(res, self.bias) # добавляем смещение (bias) для каждого батча\n",
    "        #========== v1.1\n",
    "        # for batch in res:\n",
    "        #     batch += self.bias\n",
    "        #==========\n",
    "        return res\n",
    "        \n",
    "    \n",
    "    def backward(self, grad: np.ndarray, lr: np.float64=0.01):\n",
    "        \"\"\"\n",
    "        Функция, обновляющая веса слоя и передающая градиент дальше.\\n\n",
    "        \"\"\"\n",
    "        self.w = self.w - lr * grad.sum(axis=0)/grad.shape[0] # обновляем веса (усредняя градиент по батчам)\n",
    "        # + делаем что-то со смещением\n",
    "\n",
    "\n",
    "        print(grad.shape)\n",
    "        print(self.prev_input.shape)\n",
    "        # for batch in range(grad.shape[0]): # идём по батчам\n",
    "        #     grad[batch] = 1/self.in_features * np.matmul(grad, self.prev_input)\n",
    "        \n",
    "        # grad = 1/self.in_features * np.matmul(grad, self.prev_input)\n",
    "\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(size=(10, 5))\n",
    "w = torch.randn(size=(5, 3))\n",
    "b = torch.randn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2880511 , -0.73067941,  0.80104762],\n",
       "       [-2.21654934,  1.70330536,  3.25667572],\n",
       "       [-1.58797768, -1.10032916,  1.35084105],\n",
       "       [-0.1923759 , -2.79034126,  3.99202061],\n",
       "       [-4.31068921,  3.79309046, -3.91342926],\n",
       "       [-1.30978702,  0.19246399,  4.02842474],\n",
       "       [-2.10509318,  0.47696173,  1.13921094],\n",
       "       [-1.01991095, -1.33258647, -3.6062541 ],\n",
       "       [-4.42256474,  3.90015805, -6.54223108],\n",
       "       [ 1.0639236 , -4.08856142,  0.51385152]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.zeros(shape=(10,3))\n",
    "for batch in range(10):\n",
    "    res[batch] = np.matmul(x[batch], w)\n",
    "    res[batch] = np.add(res[batch], b)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2881, -0.7307,  0.8010],\n",
       "        [-2.2165,  1.7033,  3.2567],\n",
       "        [-1.5880, -1.1003,  1.3508],\n",
       "        [-0.1924, -2.7903,  3.9920],\n",
       "        [-4.3107,  3.7931, -3.9134],\n",
       "        [-1.3098,  0.1925,  4.0284],\n",
       "        [-2.1051,  0.4770,  1.1392],\n",
       "        [-1.0199, -1.3326, -3.6063],\n",
       "        [-4.4226,  3.9002, -6.5422],\n",
       "        [ 1.0639, -4.0886,  0.5139]], dtype=torch.float64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = Linear(5, 3)\n",
    "l.w = w\n",
    "l.bias = b\n",
    "l.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2881, -0.7307,  0.8010],\n",
       "        [-2.2165,  1.7033,  3.2567],\n",
       "        [-1.5880, -1.1003,  1.3508],\n",
       "        [-0.1924, -2.7903,  3.9920],\n",
       "        [-4.3107,  3.7931, -3.9134],\n",
       "        [-1.3098,  0.1925,  4.0284],\n",
       "        [-2.1051,  0.4770,  1.1392],\n",
       "        [-1.0199, -1.3326, -3.6063],\n",
       "        [-4.4226,  3.9002, -6.5422],\n",
       "        [ 1.0639, -4.0886,  0.5139]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.matmul(x, w)\n",
    "for batch in res:\n",
    "    batch += b\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2881, -0.7307,  0.8010],\n",
       "        [-2.2165,  1.7033,  3.2567],\n",
       "        [-1.5880, -1.1003,  1.3508],\n",
       "        [-0.1924, -2.7903,  3.9920],\n",
       "        [-4.3107,  3.7931, -3.9134],\n",
       "        [-1.3098,  0.1925,  4.0284],\n",
       "        [-2.1051,  0.4770,  1.1392],\n",
       "        [-1.0199, -1.3326, -3.6063],\n",
       "        [-4.4226,  3.9002, -6.5422],\n",
       "        [ 1.0639, -4.0886,  0.5139]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(np.matmul(x, w), b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNetwork():\n",
    "    def __init__(self, in_features, out_features):\n",
    "        # 196 = 784/4, то есть уменьшили в 4 раза\n",
    "        self.linear1 = Linear(in_features, int(in_features/4)) # задаём первый линейный слой\n",
    "        self.linear2 = Linear(int(in_features/4), 10) # задаём второй линейный слой\n",
    "        self.activation = ReLU() # задаём активацию\n",
    "        self.softmax = Softmax() # задаём softmax\n",
    "        self.layers = [] # список всех слоёв модели\n",
    "        self.layers.append(self.linear1)\n",
    "        self.layers.append(self.linear2)\n",
    "        self.layers.append(self.activation)\n",
    "        self.layers.append(self.softmax)\n",
    "\n",
    "\n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция для вызова forward метода всех слоёв модели.\\n\n",
    "        Parameters:\n",
    "            * x: данные на вход размера (batch_size, channels, height, width)\\n\n",
    "        Returns:\n",
    "            * np.ndarray: результат вызова всех слоёв модели\n",
    "        \"\"\"\n",
    "        x = x.reshape(x.shape[0], x.shape[1]*x.shape[2]*x.shape[3]) # \"избавляемся\" от размерностей channels, height, width, совмещаем их в одномерный массив -> получаем двумерный массив размера (batch_size, channels*height*width)\n",
    "        for layer in self.layers: # идём по слоям модели\n",
    "            x = layer.forward(x) # последовательно вызываем forward метод каждого слоя\n",
    "        return x\n",
    "    \n",
    "\n",
    "    def backward(self, grad) -> None:\n",
    "        \"\"\"\n",
    "        Функция для обновления весов модели.\\n\n",
    "        Parameters:\n",
    "            * grad: значение градиента, используемое для обновления весов\\n\n",
    "        Returns:\n",
    "            * None: обновляет веса модели путём градиентного спуска\n",
    "        \"\"\"\n",
    "        for layer in reversed(self.layers): # идём по слоям в обратном порядке\n",
    "            grad = layer.backward(grad) # обновляем веса у слоя и возвращаем изменённый loss \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Cross-Entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Cross Entropy Loss = - \\dfrac{1}{batch\\_size} \\sum_{N=1}^{batch\\_size} \\sum_{C=1}^{classes}p^{true}_{N,C}*log_e(p^{pred}_{N,C})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Конструктор функции для подсчёта CrossEntropyLoss.\n",
    "        \"\"\"\n",
    "        self.loss = None # значение подсчитанного loss\n",
    "        self.grad = None # градиент размера (batch_size, classes)\n",
    "        self.p_pred = None\n",
    "        self.p_true = None\n",
    "    \n",
    "\n",
    "    def calc_loss(self, p_pred, p_true) -> np.float64: # результат разниться с torch.nn.CrossEntropyLoss()!\n",
    "        \"\"\"\n",
    "        Функция для подсчёта Cross-Entropy loss с усреднением по батчу.\\n\n",
    "        Parameters:\n",
    "            * p_pred: предсказанные вероятности классов размера (batch_size, classes)\n",
    "            * p_true: реальные вероятности классов размера (batch_size, classes)\\n\n",
    "        Returns:\n",
    "            * np.float64: значение функции потерь\n",
    "        \"\"\"\n",
    "        batch_size = p_true.shape[0] # размер батча\n",
    "        classes = p_true.shape[1] # число классов\n",
    "        loss = 0.0 # значение loss\n",
    "\n",
    "        p_pred[p_pred==0.0] = 0.000001 # заменяем полностью нулевые вероятности на очень малые - чтобы логарифм в формуле не давал -inf\n",
    "\n",
    "        for batch in range(batch_size): # идём по числу батчей (внешний цикл)\n",
    "            #========== v1\n",
    "            loss += np.matmul(p_true[batch], np.log(p_pred[batch])) # сумма по классам на определённом батче\n",
    "            #========== v2\n",
    "            # for c in range(classes):\n",
    "            #     loss += p_true[batch][c] * np.log(p_pred[batch][c])\n",
    "            #==========\n",
    "        loss = - loss / batch_size # домножаем на -1 и берём среднее по батчам\n",
    "\n",
    "        self.loss = loss # запоминаем подсчитанный loss\n",
    "        #========== v1\n",
    "        self.grad = np.zeros(shape=(batch_size, classes)) # заготовка под матрицу градиентов\n",
    "        #========== v2\n",
    "        # self.grad = np.zeros(shape=(1, classes)) # заготовка под матрицу градиентов (с усреднением по батчам)\n",
    "        #==========\n",
    "        self.p_pred = p_pred\n",
    "        self.p_true = p_true\n",
    "        return loss # возвращаем посчитанный loss\n",
    "    \n",
    "\n",
    "    def backward(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Функция для подсчёта градиента после Cross-Entropy loss.\\n\n",
    "        Parameters:\\n\n",
    "        Returns:\n",
    "            * np.ndarray: значение градиента размер (batch_size, classes)\n",
    "        \"\"\"\n",
    "        #========== v1\n",
    "        for batch in range(self.grad.shape[0]): # идём по номерам батчей\n",
    "            for c in range(self.grad.shape[1]): # идём по классам\n",
    "                self.grad[batch][c] = self.p_pred[batch][c] - self.p_true[batch][c] # считаем градиент (см grad.png)\n",
    "        #========== v2\n",
    "        # for batch in range(self.grad.shape[0]): # идём по номерам батчей\n",
    "        #     for c in range(self.grad.shape[1]): # идём по классам\n",
    "        #         self.grad[0][c] = self.p_pred[batch][c] - self.p_true[batch][c] # считаем градиент (см grad.png)\n",
    "        # self.grad = self.grad / self.grad.shape[0] # усредняем градиент по числу батчей\n",
    "        #==========\n",
    "        return self.grad # возвращаем посчитанный градиент\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6094379124341003"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = CrossEntropyLoss()\n",
    "l.calc_loss(np.array([[0.2,0.6,0.2]]),np.array([[1.0,0.0,0.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8,  0.6,  0.2]])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0392, 0.2646, 0.2682, 0.0679, 0.3601],\n",
       "        [0.2212, 0.3373, 0.0662, 0.0277, 0.3476],\n",
       "        [0.1323, 0.0390, 0.0318, 0.0376, 0.7592],\n",
       "        [0.1140, 0.0853, 0.0668, 0.0917, 0.6421],\n",
       "        [0.0967, 0.1964, 0.2099, 0.3126, 0.1844],\n",
       "        [0.4509, 0.3799, 0.0272, 0.0847, 0.0573],\n",
       "        [0.2932, 0.0498, 0.1674, 0.4566, 0.0330],\n",
       "        [0.1614, 0.5482, 0.1600, 0.1084, 0.0220],\n",
       "        [0.2530, 0.0439, 0.3490, 0.2195, 0.1346],\n",
       "        [0.1400, 0.3568, 0.0198, 0.2708, 0.2126]], dtype=torch.float64)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs_true = np.array([[1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0], [0,0,0,0,1], [1,0,0,0,0], [0,1,0,0,0], [0,0,1,0,0], [0,0,0,1,0], [1,0,0,0,1]], dtype=np.float64)\n",
    "probs_true = torch.tensor(probs_true)\n",
    "probs = np.random.randn(10, 5)\n",
    "probs = Softmax.forward(probs)\n",
    "probs = torch.tensor(probs)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8143, dtype=torch.float64)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_torch = torch.nn.CrossEntropyLoss()\n",
    "loss_torch(probs, probs_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2514, dtype=torch.float64)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = CrossEntropyLoss()\n",
    "l.calc_loss(probs, probs_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.96084439,  0.26462033,  0.26824507,  0.06787287,  0.36010612]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_func, num_classes): # функция обучения\n",
    "    for batch_idx, (data, target) in enumerate(train_loader): # идём по батчам, что возвращает train_loader\n",
    "        # переводим target в вероятностное пространство (везде нули, кроме нужного таргета - там единица)\n",
    "        # p_true = np.array([0.0 if i != target else 1.0 for i in range(num_classes)], dtype=np.float64) # переводим target в вероятностное пространство (везде нули, кроме нужного таргета - там единица)\n",
    "        p_true = np.zeros(shape=(train_loader.batch_size, num_classes)) # заготовка под вероятности (пока заполнена нулями)\n",
    "        for batch, t in enumerate(target): # идём по батчу (нескольких сэмплам)\n",
    "            p_true[batch][t] = 1.0 # ставим вероятность 1 у нужных таргетов (для всех элементов в батче)\n",
    "\n",
    "        data=data.numpy() # переводим данные из формата tensor в numpy.array\n",
    "\n",
    "        p_preds = model.forward(data) # вызываем forward pass модели (предсказываем)\n",
    "        loss = loss_func.calc_loss(p_preds, p_true) # считаем loss модели\n",
    "        grad = loss_func.backward() # считаем градиент ошибки\n",
    "        model.backward(grad) # обновляем веса модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Documents\\TEMP\\ipykernel_38980\\3543284042.py:16: RuntimeWarning: overflow encountered in exp\n",
      "  e = np.exp(x) # считаем экспоненту от всех элементов X (каждый элемент в X идёт как степень e)\n",
      "C:\\Users\\User\\Documents\\TEMP\\ipykernel_38980\\3543284042.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  e[batch] = e[batch] / e[batch].sum() # каждый элемент (экспоненту) в батче делим на сумму экспонент этого батча\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "(10, 196)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (784,196) (10,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\документы\\учёба\\магистратура (ИАД 2023-2025)\\курс 1\\5) НИС - Инструменты интеллектуального анализа данных\\labs\\lab2\\task2.ipynb Cell 44\u001b[0m line \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m CustomNetwork(in_features\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mprod(data_train[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape), out_features\u001b[39m=\u001b[39mnum_classes) \u001b[39m# np.prod(data_train[0][0].shape) - произведение всех размерностей входных данных\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loss_func \u001b[39m=\u001b[39m CrossEntropyLoss()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train(model\u001b[39m=\u001b[39;49mmodel, train_loader\u001b[39m=\u001b[39;49mtrain_loader, loss_func\u001b[39m=\u001b[39;49mloss_func, num_classes\u001b[39m=\u001b[39;49mnum_classes)\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\документы\\учёба\\магистратура (ИАД 2023-2025)\\курс 1\\5) НИС - Инструменты интеллектуального анализа данных\\labs\\lab2\\task2.ipynb Cell 44\u001b[0m line \u001b[0;36mtrain\u001b[1;34m(model, train_loader, loss_func, num_classes)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func\u001b[39m.\u001b[39mcalc_loss(p_preds, p_true) \u001b[39m# считаем loss модели\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m grad \u001b[39m=\u001b[39m loss_func\u001b[39m.\u001b[39mbackward() \u001b[39m# считаем градиент ошибки\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m model\u001b[39m.\u001b[39;49mbackward(grad)\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\документы\\учёба\\магистратура (ИАД 2023-2025)\\курс 1\\5) НИС - Инструменты интеллектуального анализа данных\\labs\\lab2\\task2.ipynb Cell 44\u001b[0m line \u001b[0;36mCustomNetwork.backward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mФункция для обновления весов модели.\\n\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m    * None: обновляет веса модели путём градиентного спуска\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers): \u001b[39m# идём по слоям в обратном порядке\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     grad \u001b[39m=\u001b[39m layer\u001b[39m.\u001b[39;49mbackward(grad)\n",
      "\u001b[1;32mc:\\Users\\User\\Desktop\\документы\\учёба\\магистратура (ИАД 2023-2025)\\курс 1\\5) НИС - Инструменты интеллектуального анализа данных\\labs\\lab2\\task2.ipynb Cell 44\u001b[0m line \u001b[0;36mLinear.backward\u001b[1;34m(self, grad, lr)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(\u001b[39mself\u001b[39m, grad: np\u001b[39m.\u001b[39mndarray, lr: np\u001b[39m.\u001b[39mfloat64\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m    Функция, обновляющая веса слоя и передающая градиент дальше.\\n\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw \u001b[39m-\u001b[39;49m lr \u001b[39m*\u001b[39;49m grad\u001b[39m.\u001b[39;49msum(axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m/\u001b[39;49mgrad\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m] \u001b[39m# обновляем веса (усредняя градиент по батчам)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m# + делаем что-то со смещением\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/User/Desktop/%D0%B4%D0%BE%D0%BA%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B/%D1%83%D1%87%D1%91%D0%B1%D0%B0/%D0%BC%D0%B0%D0%B3%D0%B8%D1%81%D1%82%D1%80%D0%B0%D1%82%D1%83%D1%80%D0%B0%20%28%D0%98%D0%90%D0%94%202023-2025%29/%D0%BA%D1%83%D1%80%D1%81%201/5%29%20%D0%9D%D0%98%D0%A1%20-%20%D0%98%D0%BD%D1%81%D1%82%D1%80%D1%83%D0%BC%D0%B5%D0%BD%D1%82%D1%8B%20%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D1%83%D0%B0%D0%BB%D1%8C%D0%BD%D0%BE%D0%B3%D0%BE%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85/labs/lab2/task2.ipynb#Y235sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39mprint\u001b[39m(grad\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (784,196) (10,) "
     ]
    }
   ],
   "source": [
    "num_classes = 10 # число классов (различных цифр)\n",
    "model = CustomNetwork(in_features=np.prod(data_train[0][0].shape), out_features=num_classes) # np.prod(data_train[0][0].shape) - произведение всех размерностей входных данных\n",
    "loss_func = CrossEntropyLoss()\n",
    "train(model=model, train_loader=train_loader, loss_func=loss_func, num_classes=num_classes)\n",
    "# loss - кросс-энтропия (перекрёстная энтропия)\n",
    "# CrossEntropyLoss на вход ожидает вероятность класса для всех k классов\n",
    "# то есть массив с вероятностями для каждой из четырёх категорий новостей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()\n",
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss() # определяем функцию потерь — бинарную кросс-энтропию (хорошо для задачи бинарной классификации, где таргет может принимать лишь два значения - 0 и 1)\n",
    "# При бинарной классификации каждая предсказанная вероятность сравнивается с фактическим значением класса (0 или 1), \n",
    "# и вычисляется оценка, которая штрафует вероятность на основе расстояния от ожидаемого значения.\n",
    "\n",
    "# BCELoss выше, чем MSEloss примерно раза в 4 (на выбранном датасете), поэтому значение в 0.4 для BCE — это хорошо\n",
    "model_log = CustomNetwork(X_train.shape[1], Y_train.shape[1]).to(torch.float64) # создаём объект модели\n",
    "\n",
    "optimizer_1 = optim.Adam(model_log.parameters(), lr=learning_rate) # определяем оптимайзер — Adam и передаём в него веса модели с lr\n",
    "\n",
    "for epoch in range(num_epochs): # проводим обучение и тестирование num_epochs раз\n",
    "    Y_pred = model_log(X_train) # делаем предсказание\n",
    "    loss = criterion(Y_pred, Y_train) # считаем ошибку по BCE loss\n",
    "\n",
    "    losses[\"LogisticRegression\"][\"train\"].append(loss.data) # запоминаем значение BCEloss\n",
    "\n",
    "    optimizer_1.zero_grad() # обнуляем градиенты во всех обучаемых torch.Tensor (ставит w.grad = 0 в torch.Tensor с requires_grad=True) (вызывается перед loss.backward(), чтобы не аккумулировать градиенты за несколько итераций обучения)\n",
    "    loss.backward() # считаем dloss/dw для каждого веса модели w, у которого requires_grad=True (сохраняется в w.grad следующим образом w.grad += dloss/dw)\n",
    "    optimizer_1.step() # обновляет веса модели (тензоры, у которых стоит флаг requires_grad=True, используя значение из w.grad следующим образом w += -lr * w.grad)\n",
    "\n",
    "    with torch.no_grad(): # запускаем валидацию (каждую эпоху)\n",
    "        Y_pred = model_log(X_test) # вызываем forward с передачей X_test\n",
    "        losses[\"LogisticRegression\"][\"test\"].append(criterion(Y_pred, Y_test).data) # запоминаем значение BCEloss\n",
    "plt.figure(figsize=(10,8)) # задание размера графика\n",
    "plt.plot(losses[\"LogisticRegression\"][\"train\"], \"b\", label='train') # построение BCE loss на обучении\n",
    "plt.plot(losses[\"LogisticRegression\"][\"test\"], \"r\", label='test') # построение BCE loss на тестировании\n",
    "\n",
    "plt.title('BCE Loss with LogisticRegression') # название графика\n",
    "plt.xlabel('epoch') # подпись по оси x\n",
    "plt.ylabel('loss') # подпись по оси y\n",
    "plt.legend() # вывод названий графиков\n",
    "plt.show() # вывод графика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всякие тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = torch.nn.Linear(10,100,bias = True)\n",
    "linear.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
