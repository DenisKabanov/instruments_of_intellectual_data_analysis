{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание: \n",
    "Для каждого кадра с камеры 1 нужно найти соответствующий (ближайший по времени) кадр с камеры 2. \n",
    "* Камеры записывают в формате (номер кадра, время его захвата) ~ (frame, timestamp).\n",
    "* Камеры могут делать запись с разной частотой кадров в секунду и наличием шума (несоответствии времени кадра ожидаемому времени)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройки/Гиперпараметры/Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time # для подсчёта времени работы\n",
    "import numpy as np # для быстрой работы с массивами\n",
    "from multiprocessing import Pool # для параллельного запуска (нужны процессы, а не потоки из multithreading/concurrent.futures)\n",
    "from numba import njit, prange # импорт компилятора для ускорения питона (prange для параллелизации)\n",
    "from numba import float64, int32 # для создания сигнатур (почему-то крашится, поэтому в коде использование закоменчено)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores_number = 2 # число ядер, на которые будет распараллеливаться выполнение кода\n",
    "runs = 5 # число запусков для усреднения времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_timestamps(fps: int, st_ts: float, fn_ts: float) -> np.ndarray: # функция генерации записей с камеры\n",
    "    \"\"\"\n",
    "    Создаёт np.array timestamps (массив времени записи кадра). \n",
    "    Этот массив дискретизирован по fps, но не равномерно.\n",
    "    Возвращаемые timestamps отсортированы и уникальны.\\n\n",
    "    Parameters:\n",
    "        * fps: среднее число кадров в секунду\n",
    "        * st_ts: первый timestamp в последовательности (время первого кадра)\n",
    "        * fn_ts: первый timestamp в последовательности (время последнего кадра) \\n\n",
    "    Returns:\n",
    "        * np.ndarray: сгенерированные timestamps (массивы времени записи кадра)\n",
    "    \"\"\"\n",
    "    timestamps = np.linspace(st_ts, fn_ts, int((fn_ts - st_ts) * fps)) # создаём временные записи из равномерного распределения\n",
    "    timestamps += np.random.randn(len(timestamps)) # зашумляем кадры\n",
    "    timestamps = np.unique(np.sort(timestamps)) # сортируем кадры по времени и оставляем только уникальные\n",
    "    return timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_average_time(alg, data, runs: int=100) -> (float, np.ndarray): # функция для подсчёта среднего времени работы алгоритма\n",
    "    \"\"\"\n",
    "    Функция для подсчёта среднего времени работы алгоритма.\\n\n",
    "    Parameters:\n",
    "        * alg: алгоритм для тестирования\n",
    "        * data: данные на вход алгоритма\n",
    "        * runs: число запусков для усреднения времени\n",
    "    Returns:\n",
    "        * float: среднее время работы\n",
    "        * np.ndarray: получившийся ответ\n",
    "    \"\"\"\n",
    "    time_start = time.perf_counter() # замеряем время начала\n",
    "    for i in range(runs): # делаем runs запусков\n",
    "        answer = alg(*data) # вызываем алгоритм (*data для развёртывания переданных данных для алгоритма, если они в list-like формате)\n",
    "        print(i, (time.perf_counter() - time_start)/(i+1)) # вывод среднего времени i-ой итерации (i+1 из-за нумерации с нуля)\n",
    "    time_average = (time.perf_counter() - time_start) / runs # считаем среднее время\n",
    "    return time_average, answer # возвращаем среднее время и получившийся ответ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate timestamps for the first camera\n",
    "# timestamps1 = make_timestamps(30, time.time() - 100, time.time() + 3600 * 2)\n",
    "# generate timestamps for the second camera\n",
    "# timestamps2 = make_timestamps(60, time.time() + 200, time.time() + 3600 * 2.5)\n",
    "\n",
    "timestamps1 = make_timestamps(30, time.time() - 100, time.time() + 900 * 2) # не 3600 (60 секунд * 60 минут), а лишь (15 * 60) = 15 минут\n",
    "timestamps2 = make_timestamps(60, time.time() + 200, time.time() + 900 * 2.5) # не 3600 (60 секунд * 60 минут), а лишь (15 * 60) = 15 минут"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56998,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Варианты решения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Глупо считаем разницу во времени между i-м кадром с первой камеры и всеми кадрами со второй камеры. В ответ записываем номер кадра со второй камеры с наименьшим модулем разности времени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit #====================== использовать ли numba компилятор для функции ============================\n",
    "def match_timestamps_naive(timestamps1: np.ndarray, timestamps2: np.ndarray) -> np.ndarray: \n",
    "    \"\"\"\n",
    "    * Делаем для каждого элемента первого массива: - O(n)\n",
    "            * из всех элементов второго массива вычитается элемент первого массива (считаем delta) за O(2n) ~ O(n)\n",
    "            * в получившихся delta ищем наименьший элемент за O(2n) ~ O(n)\\n\n",
    "    Итоговая сложность: O(размер_первого_массива * (размер_второго_массива + размер_второго_массива)) = O(n*(2n+2n)) = O(4n^2) ~ O(n^2)\n",
    "    Parameters:\n",
    "        * timestamps1: массив с временами с камеры 1\n",
    "        * timestamps2: массив с временами с камеры 2\\n\n",
    "    Returns:\n",
    "        * np.ndarray: массив соответствий кадров с камеры 1 к кадрам камеры 2\n",
    "    \"\"\"\n",
    "    \n",
    "    # так как в задании первая камера пишет в ~30 fps -> размер первого массива n; вторая камера пишет в ~60 fps -> размер второго массива не сильно больше 2n; сокращаем на константы и получаем n\n",
    "    frames_count = timestamps1.shape[0] # число кадров на камере 1\n",
    "    correspondence = np.zeros(frames_count, dtype=np.int32) # создаём массив под номера кадров с типом int32 для уменьшения потребляемой памяти\n",
    "\n",
    "    #===================== вариант с циклом в np.arange ================================================\n",
    "    # for frame in np.arange(frames_count): # идём по номерам кадров с первой камеры\n",
    "    #--------------------- вариант с циклом в enumerate ------------------------------------------------\n",
    "    for frame, frame_time in enumerate(timestamps1): # идём по кадрам\n",
    "    #===================================================================================================\n",
    "        #===================== вариант с сохранением delta =============================================\n",
    "        # deltas = np.absolute(timestamps2 - timestamps1[frame]) # считаем разницу между временами\n",
    "        # correspondence[frame] = deltas.argmin() # берём номер кадра с наименьшей разницей\n",
    "        #--------------------- вариант без сохранения delta --------------------------------------------\n",
    "        correspondence[frame] = np.absolute(timestamps2 - frame_time).argmin() # цикл с enumerate\n",
    "        # correspondence[frame] = np.absolute(timestamps2 - timestamps1[frame]).argmin() # цикл с np.arange\n",
    "        #===============================================================================================\n",
    "\n",
    "    return correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 24.950418900000386\n",
      "1 20.281998550000026\n",
      "2 19.04419333333347\n",
      "3 18.18515685\n",
      "4 17.745648980000077\n"
     ]
    }
   ],
   "source": [
    "true_time, true_answer = calc_average_time(match_timestamps_naive, (timestamps1, timestamps2), runs=runs) # njit, цикл в enumerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- naive no njit + np.arange ~ 20.0 - 70.0 секунд\n",
    "- naive no njit + enumerate ~ 18.0 - 19.0 секунд\n",
    "- naive njit    + np.arange ~ 15.5 - 15.8 секунд\n",
    "- naive njit    + enumerate ~ 15.0 - 15.7 секунд\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Параллельная версия первого алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import match_timestamps_naive # импорт функции, так как в notebook multiprocessing навсегда зависает при вызове функции из этого же notebook (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_timestamps_naive_parallel(timestamps1: np.ndarray, timestamps2: np.ndarray, func, cores_number: np.int8) -> np.ndarray: \n",
    "    \"\"\"\n",
    "    * Делаем для каждого элемента первого массива с распараллеливанием: - O(n/cores_number)\n",
    "            * из всех элементов второго массива вычитается элемент первого массива (считаем delta) за O(2n) ~ O(n)\n",
    "            * в получившихся delta ищем наименьший элемент за O(2n) ~ O(n)\\n\n",
    "    Итоговая сложность: O(размер_первого_массива / число_ядер * (размер_второго_массива + размер_второго_массива)) = O(n/cores_number*(2n+2n)) = O(4/cores_number*n^2) ~ O(n^2/cores_number)\\n\n",
    "    Parameters:\n",
    "        * timestamps1: массив с временами с камеры 1\n",
    "        * timestamps2: массив с временами с камеры 2\n",
    "        * func: запускаемая в параллель функция\n",
    "        * cores_number: число ядер, на которое будет распараллеливание\\n\n",
    "    Returns:\n",
    "        * np.ndarray: массив соответствий кадров с камеры 1 к кадрам камеры 2\n",
    "    \"\"\"\n",
    "\n",
    "    # так как в задании первая камера пишет в ~30 fps -> размер первого массива n; вторая камера пишет в ~60 fps -> размер второго массива 2n; сокращаем на константы и получаем n\n",
    "    frames_count = timestamps1.shape[0] # число кадров с первой камеры\n",
    "    with Pool(cores_number) as p: # запускаем cores_number процессов\n",
    "        correspondence = np.concatenate(p.starmap(func, [(timestamps1[int(i*frames_count/cores_number):int((i+1)*frames_count/cores_number)], timestamps2) for i in np.arange(cores_number)]), dtype=np.int32)\n",
    "        #  - каждому процессу отправляем равную часть кадров с первой камеры и все кадры со второй\n",
    "        #  - конкатенируем вернувшиеся из процессов массивы с индексами\n",
    "        # процесс вызывает переданную функцию func с параметрами: срез кадров с первой камеры, все кадры второй камеры\n",
    "        # не обязательно передавать chunksize, так как распараллеливание уже идёт по кейсам/инпутам для функций\n",
    "        # dtype=np.int32 для уменьшения потребляемой памяти и ускорения работы\n",
    "\n",
    "    return correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10.85389529999975\n",
      "1 11.15200354999979\n",
      "2 11.337617466666567\n",
      "3 11.252855424999893\n",
      "4 11.30571489999993\n"
     ]
    }
   ],
   "source": [
    "time_naive_parallel, answer_naive_parallel = calc_average_time(match_timestamps_naive_parallel, (timestamps1, timestamps2, match_timestamps_naive, cores_number), runs=runs) # подсчёт среднего времени (с njit и enumerate циклом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(answer_naive_parallel==true_answer) # проверка, что параллельная функция отработала корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- parallel naive no njit + np.arange ~ 40.0 - 41.0 секунд\n",
    "- parallel naive no njit + enumerate ~ 41.0 - 43.0 секунд\n",
    "- parallel naive njit    + np.arange ~ 11.2 - 12.0 секунд\n",
    "- parallel naive njit    + enumerate ~ 10.0 - 11.3 секунд\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Идём по последовательности кадров с первой камеры, запоминанием найденное соответствие со второй (номер delta, после которого разница во времени начинают увеличиваться). На следующем шаге по кадрам на второй камере начинаем идти с найденного соответствия на предыдущем шаге (так как кадры отсортированы в порядке неубывания - нет смысла рассматривать кадры, что заведомо имеют большую delta из-за увеличения времени на первой камере)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @njit(float64[:](float64[:], float64[:], int32)) # использовать ли numba компилятор для функции с заданием сигнатуры для изначальной компиляции\n",
    "@njit #====================== использовать ли numba компилятор для функции ============================\n",
    "def match_timestamps_iterated(timestamps1: np.ndarray, timestamps2: np.ndarray, cam2_frame: np.int32=0) -> np.ndarray: \n",
    "    \"\"\"\n",
    "    * Ищем начальный кадр для второй камеры - O(2n), однако реальная сложность меньше, так как cam2_frame уже найден эвристически с учётом числа кадров на первой и второй камере\n",
    "    * Делаем для каждого элемента (времени) с первой камеры: - O(n)\n",
    "            * Вычитаем из соответствующего времени кадра второй камеры значение времени кадра с первой камеры - O(2n) в худшем случае, O(2) ~ O(1) в среднем, так как кадры распределены равномерно и во втором массиве не на порядок больше элементов\n",
    "                    * если дельта уменьшилась - переходим к следующему кадру на второй камере и так далее, пока дельта уменьшается\\n\n",
    "                    * если дельта не уменьшилась - возвращаем предыдущий кадр, как самый близкий по времени\\n\n",
    "    Итоговая сложность: O(размер_второго_массива + размер_первого_массива * размер_второго_массива) ~ [в среднем] ~ O(размер_второго_массива + размер_первого_массива * 1) ~ O(n)\\n\n",
    "    Parameters:\n",
    "        * timestamps1: массив с временами с камеры 1\n",
    "        * timestamps2: массив с временами с камеры 2\n",
    "        * cam2_frame: с какого элемента рассматривать кадры с камеры 2 (важен при параллельном запуске)\\n\n",
    "    Returns:\n",
    "        * np.ndarray: массив соответствий кадров с камеры 1 к кадрам камеры 2\n",
    "    \"\"\"\n",
    "    \n",
    "    # так как в задании первая камера пишет в ~30 fps -> размер первого массива n; вторая камера пишет в ~60 fps -> размер второго массива не сильно больше 2n; сокращаем на константы и получаем n\n",
    "    frames_count = timestamps1.shape[0] # число кадров на камере 1\n",
    "    max_frame = timestamps2.shape[0] - 1 # максимальный номер кадра, что может соответствовать кадру с первой камеры (-1 из-за индексации с нуля)\n",
    "    correspondence = np.zeros(frames_count, dtype=np.int32) # создаём массив под номера кадров с типом int32 для уменьшения потребляемой памяти\n",
    "\n",
    "    if 0 > cam2_frame or cam2_frame > max_frame: # защита от дурака с cam2_frame\n",
    "        cam2_frame = 0 # зануление начального кадра второй камеры\n",
    "\n",
    "    # подбираем кадр на второй камере, с которого будем начинать (эвристически уже передали ожидаемый cam2_frame, нужно его лишь правильно сместить, если он \"обогнал\" кадры с камеры 1)\n",
    "    delta = np.abs(timestamps2[cam2_frame] - timestamps1[0]) # текущая разность времени\n",
    "    while np.abs(timestamps2[max(0, cam2_frame-1)] - timestamps1[0]) < delta: # если дельта уменьшается при предыдущем кадре, то переходим на него (условие — строго меньше, так как времена всех кадров уникальны)\n",
    "        cam2_frame -= 1 # переходим на предыдущий кадр (без max, так как при нуле мы бы сюда не зашли в цикл)\n",
    "        delta = np.abs(timestamps2[cam2_frame] - timestamps1[0]) # обновляем текущее значение delta (без max, так как при нуле мы бы не зашли в цикл)\n",
    "    # после этого цикла мы либо находимся на оптимальном соответствии первого кадра первой камеры с кадром со второй камеры, либо оптимум — далее по времени (но не раньше!)\n",
    "\n",
    "    #===================== вариант с циклом в np.arange ================================================\n",
    "    # for frame in np.arange(frames_count): # идём по номерам кадров с первой камеры\n",
    "    #     delta = np.abs(timestamps2[cam2_frame] - timestamps1[frame]) # текущая разность времени\n",
    "    #     while np.abs(timestamps2[min(cam2_frame+1, max_frame)] - timestamps1[frame]) < delta: # если при переходе на следующий кадр дельта (разница времени) уменьшилась, то обновляем delta и соответствующий кадр на второй камере \n",
    "    #         cam2_frame += 1 # переходим на следующий кадр\n",
    "    #         delta = np.abs(timestamps2[cam2_frame] - timestamps1[frame])  # обновляем delta\n",
    "    #     correspondence[frame] = cam2_frame # если дельта перестала уменьшаеться — записываем найденный кадр\n",
    "    #--------------------- вариант с циклом в enumerate ------------------------------------------------\n",
    "    for frame, frame_time in enumerate(timestamps1): # идём по кадрам (frame - номер кадра на первой камере, frame_time - время его запечатления)\n",
    "        delta = np.abs(timestamps2[cam2_frame] - frame_time) # текущая разность времени\n",
    "        while np.abs(timestamps2[min(cam2_frame+1, max_frame)] - frame_time) < delta: # если при переходе на следующий кадр дельта (разница времени) уменьшилась, то обновляем delta и соответствующий кадр на второй камере \n",
    "            cam2_frame += 1 # переходим на следующий кадр\n",
    "            delta = np.abs(timestamps2[cam2_frame] - frame_time)  # обновляем delta\n",
    "        correspondence[frame] = cam2_frame # если дельта перестала уменьшаеться — записываем найденный кадр\n",
    "    #===============================================================================================\n",
    "\n",
    "    return correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5652193999999326\n",
      "1 0.2838906499998757\n",
      "2 0.18977626666658884\n",
      "3 0.14298617500003274\n",
      "4 0.1151557999999568\n"
     ]
    }
   ],
   "source": [
    "time_iterated, answer_iterated = calc_average_time(match_timestamps_iterated, (timestamps1, timestamps2), runs=runs) # подсчёт среднего времени (с njit и enumerate циклом)\n",
    "# время сильно разнится из-за создания бинаря для функции с njit при первом запуске (последующие запуски идут всегда быстрее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(answer_iterated==true_answer) # проверка, что функция отработала корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- iterated no njit + np.arange ~ 0.7451 секунд\n",
    "- iterated no njit + enumerate ~ 0.6525 секунд\n",
    "- iterated njit    + np.arange ~ 0.0882 секунд\n",
    "- iterated njit    + enumerate ~ 0.0795 секунд\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Параллельная реализация третьего алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from funcs import match_timestamps_iterated # импорт функции, так как в notebook multiprocessing навсегда зависает при вызове функции из этого же notebook (???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_timestamps_iterated_parallel(timestamps1: np.ndarray, timestamps2: np.ndarray, func, cores_number: np.int8) -> np.ndarray: \n",
    "    \"\"\"\n",
    "    * Ищем начальный кадр для второй камеры - O(2n), однако реальная сложность меньше, так как cam2_frame уже найден эвристически с учётом числа кадров на первой и второй камере\n",
    "    * Делаем для каждого элемента первого массива (времени) с распараллеливанием: - O(n/cores_number)\n",
    "            * Вычитаем из соответствующего времени кадра второй камеры значение времени кадра с первой камеры - O(2n) в худшем случае, O(2) ~ O(1) в среднем, так как кадры распределены равномерно и во втором массиве не на порядок больше элементов\n",
    "                    * если дельта уменьшилась - переходим к следующему кадру на второй камере и так далее, пока дельта уменьшается\n",
    "                    * если дельта не уменьшилась - возвращаем предыдущий кадр, как самый близкий по времени\\n\n",
    "    Итоговая сложность: O(размер_второго_массива + размер_первого_массива / число_ядер * размер_второго_массива) ~ [в среднем] ~ O(размер_второго_массива + размер_первого_массива / число_ядер * 1) ~ O(n/cores_number)\\n\n",
    "    Parameters:\n",
    "        * timestamps1: массив с временами с камеры 1\n",
    "        * timestamps2: массив с временами с камеры 2\n",
    "        * func: запускаемая в параллель функция\n",
    "        * cores_number: число ядер, на которое будет распараллеливание\\n\n",
    "    Returns:\n",
    "        * np.ndarray: массив соответствий кадров с камеры 1 к кадрам камеры 2\n",
    "    \"\"\"\n",
    "\n",
    "    # так как в задании первая камера пишет в ~30 fps -> размер первого массива n; вторая камера пишет в ~60 fps -> размер второго массива 2n; сокращаем на константы и получаем n\n",
    "    frames_count = timestamps1.shape[0] # число кадров с первой камеры\n",
    "    with Pool(cores_number) as p: # запускаем cores_number процессов\n",
    "        correspondence = np.concatenate(p.starmap(func, [(timestamps1[int(i*frames_count/cores_number):int((i+1)*frames_count/cores_number)], timestamps2, int(2*i*frames_count/cores_number)) for i in np.arange(cores_number)]), dtype=np.int32)\n",
    "        #  - каждому процессу отправляем равную часть кадров с первой камеры и все кадры со второй, а также ожидаемый номер соответствия первого кадра на камере 1 с камерой 2\n",
    "        #  - конкатенируем вернувшиеся из процессов массивы с индексами\n",
    "        # процесс вызывает переданную функцию func с параметрами: срез кадров с первой камеры, все кадры второй камеры, а также ожидаемый номер соответствия первого кадра на камере 1 с камерой 2\n",
    "        # не обязательно передавать chunksize, так как распараллеливание уже идёт по кейсам/инпутам для функций\n",
    "        # dtype=np.int32 для уменьшения потребляемой памяти и ускорения работы\n",
    "\n",
    "    return correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.9934794000000693\n",
      "1 3.0763882999999623\n",
      "2 2.9628640333333656\n",
      "3 2.8483673499999895\n",
      "4 2.729524000000038\n"
     ]
    }
   ],
   "source": [
    "time_iterated_parallel, answer_iterated_parallel = calc_average_time(match_timestamps_iterated_parallel, (timestamps1, timestamps2, match_timestamps_iterated, cores_number), runs=runs) # подсчёт среднего времени (с njit и enumerate циклом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(answer_iterated_parallel==true_answer) # проверка, что функция отработала корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- parallel iterated no njit + np.arange ~ 1.3736 секунд\n",
    "- parallel iterated no njit + enumerate ~ 1.3057 секунд\n",
    "- parallel iterated njit    + np.arange ~ 2.4365 секунд\n",
    "- parallel iterated njit    + enumerate ~ 2.1035 секунд\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5*) Magnum Opus — немного переосмысленный третий алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit # использование компилятора\n",
    "def match_timestamps_iterated_v2(timestamps1: np.array, timestamps2: np.array, cores_number: np.int8=1) -> np.array:\n",
    "    \"\"\"\n",
    "    * Ищем начальный кадр для второй камеры - O(2n), однако реальная сложность меньше, так как cam2_frame уже найден эвристически с учётом числа кадров на первой и второй камере\n",
    "    * Делаем для каждого элемента (времени) с первой камеры: - O(n)\n",
    "            * Вычитаем из соответствующего времени кадра второй камеры значение времени кадра с первой камеры - O(2n) в худшем случае, O(2) ~ O(1) в среднем, так как кадры распределены равномерно и во втором массиве не на порядок больше элементов\n",
    "                    * если дельта уменьшилась - переходим к следующему кадру на второй камере и так далее, пока дельта уменьшается\\n\n",
    "                    * если дельта не уменьшилась - возвращаем предыдущий кадр, как самый близкий по времени\\n\n",
    "    Итоговая сложность: O(размер_второго_массива + размер_первого_массива * размер_второго_массива) ~ [в среднем] ~ O(размер_второго_массива + размер_первого_массива * 1) ~ O(n)\\n\n",
    "    Parameters:\n",
    "        * timestamps1: массив с временами с камеры 1\n",
    "        * timestamps2: массив с временами с камеры 2\n",
    "        * cores_number: число ядер для распараллеливания\\n\n",
    "    Returns:\n",
    "        * np.ndarray: массив соответствий кадров с камеры 1 к кадрам камеры 2\n",
    "    \"\"\"\n",
    "    frames_count = timestamps1.shape[0] # число кадров на камере 1\n",
    "    correspondence = np.full(shape=frames_count, fill_value=-1, dtype=np.int32) # создаём массив под номера кадров с типом int32 для уменьшения потребляемой памяти\n",
    "    max_frame = timestamps2.shape[0] - 1  # максимальный номер кадра, что может соответствовать кадру с первой камеры (-1 из-за индексации с нуля)\n",
    "    for proc_id in prange(cores_number): # разделяем задачу на проессы\n",
    "        t1_start = int(proc_id*frames_count/cores_number) # # с какого элемента рассматриваем кадры с первой камеры \n",
    "        t1_end = int((proc_id+1)*frames_count/cores_number) # по какой элемент рассматриваем кадры с первой камеры (без -1, так как slice не включает последний элемент)\n",
    "        cam2_frame = int(2*proc_id*frames_count/cores_number) # с какого элемента рассматривать кадры с камеры 2 (важен при параллельном запуске)\n",
    "        \n",
    "        if 0 > cam2_frame or cam2_frame > max_frame: # защита от дурака с cam2_frame\n",
    "            cam2_frame = 0 # зануление начального кадра второй камеры\n",
    "\n",
    "        # подбираем кадр на второй камере, с которого будем начинать (эвристически уже передали ожидаемый cam2_frame, нужно его лишь правильно сместить, если он \"обогнал\" кадры с камеры 1)\n",
    "        delta = np.abs(timestamps2[cam2_frame] - timestamps1[t1_start]) # текущая разность времени\n",
    "        while np.abs(timestamps2[max(0, cam2_frame-1)] - timestamps1[t1_start]) < delta: # если дельта уменьшается при предыдущем кадре, то переходим на него (условие — строго меньше, так как времена всех кадров уникальны)\n",
    "            cam2_frame -= 1 # переходим на предыдущий кадр (без max, так как при нуле мы бы сюда не зашли в цикл)\n",
    "            delta = np.abs(timestamps2[cam2_frame] - timestamps1[t1_start]) # обновляем текущее значение delta\n",
    "        # после этого цикла мы либо находимся на оптимальном соответствии первого кадра первой камеры с кадром со второй камеры, либо оптимум — далее по времени (но не раньше!)\n",
    "\n",
    "        t1_current = t1_start # текущий кадр\n",
    "        for _, frame_time in enumerate(timestamps1[t1_start:t1_end]): # идём по кадрам (_ - номер кадра на первой камере, frame_time - время его запечатления)\n",
    "            delta = np.abs(timestamps2[cam2_frame] - frame_time) # текущая разность времени\n",
    "            while np.abs(timestamps2[min(cam2_frame+1, max_frame)] - frame_time) < delta: # если при переходе на следующий кадр дельта (разница времени) уменьшилась, то обновляем delta и соответствующий кадр на второй камере \n",
    "                cam2_frame += 1 # переходим на следующий кадр\n",
    "                delta = np.abs(timestamps2[cam2_frame] - frame_time)  # обновляем delta\n",
    "            correspondence[t1_current] = cam2_frame # если дельта перестала уменьшаеться — записываем найденный кадр с учётом сдвига от параллельного выполнения\n",
    "            t1_current += 1 # изменяем текущий кадр\n",
    "    return correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4678132999997615\n",
      "1 0.23447880000003352\n",
      "2 0.156625333333371\n",
      "3 0.11768195000001924\n",
      "4 0.09431329999997615\n"
     ]
    }
   ],
   "source": [
    "time_iterated_v2, answer_iterated_v2 = calc_average_time(match_timestamps_iterated_v2, (timestamps1, timestamps2, 1), runs=runs) # подсчёт среднего времени (с njit и enumerate циклом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(answer_iterated_v2==true_answer) # проверка, что функция отработала корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- iterated v2 ~ 0.0943 - 0.4678 секунд\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6*) Параллельная реализация пятого алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True) # использование компилятора с параллельным запуском\n",
    "def match_timestamps_iterated_v2_parallel(timestamps1: np.array, timestamps2: np.array, cores_number: np.int8) -> np.array:\n",
    "    \"\"\"\n",
    "    * Ищем начальный кадр для второй камеры - O(2n), однако реальная сложность меньше, так как cam2_frame уже найден эвристически с учётом числа кадров на первой и второй камере\n",
    "    * Делаем для каждого элемента (времени) с первой камеры: - O(n/cores_number)\n",
    "            * Вычитаем из соответствующего времени кадра второй камеры значение времени кадра с первой камеры - O(2n) в худшем случае, O(2) ~ O(1) в среднем, так как кадры распределены равномерно и во втором массиве не на порядок больше элементов\n",
    "                    * если дельта уменьшилась - переходим к следующему кадру на второй камере и так далее, пока дельта уменьшается\\n\n",
    "                    * если дельта не уменьшилась - возвращаем предыдущий кадр, как самый близкий по времени\\n\n",
    "    Итоговая сложность: O(размер_второго_массива + размер_первого_массива / число ядер * размер_второго_массива) ~ [в среднем] ~ O(размер_второго_массива + размер_первого_массива / число ядер * 1) ~ O(n/cores_number)\\n\n",
    "    Parameters:\n",
    "        * timestamps1: массив с временами с камеры 1\n",
    "        * timestamps2: массив с временами с камеры 2\n",
    "        * cores_number: число ядер для распараллеливания\\n\n",
    "    Returns:\n",
    "        * np.ndarray: массив соответствий кадров с камеры 1 к кадрам камеры 2\n",
    "    \"\"\"\n",
    "    frames_count = timestamps1.shape[0] # число кадров на камере 1\n",
    "    correspondence = np.full(shape=frames_count, fill_value=-1, dtype=np.int32) # создаём массив под номера кадров с типом int32 для уменьшения потребляемой памяти\n",
    "    max_frame = timestamps2.shape[0] - 1  # максимальный номер кадра, что может соответствовать кадру с первой камеры (-1 из-за индексации с нуля)\n",
    "    for proc_id in prange(cores_number): # разделяем задачу на проессы\n",
    "        t1_start = int(proc_id*frames_count/cores_number) # # с какого элемента рассматриваем кадры с первой камеры \n",
    "        t1_end = int((proc_id+1)*frames_count/cores_number) # по какой элемент рассматриваем кадры с первой камеры (без -1, так как slice не включает последний элемент)\n",
    "        cam2_frame = int(2*proc_id*frames_count/cores_number) # с какого элемента рассматривать кадры с камеры 2 (важен при параллельном запуске)\n",
    "        \n",
    "        if 0 > cam2_frame or cam2_frame > max_frame: # защита от дурака с cam2_frame\n",
    "            cam2_frame = 0 # зануление начального кадра второй камеры\n",
    "\n",
    "        # подбираем кадр на второй камере, с которого будем начинать (эвристически уже передали ожидаемый cam2_frame, нужно его лишь правильно сместить, если он \"обогнал\" кадры с камеры 1)\n",
    "        delta = np.abs(timestamps2[cam2_frame] - timestamps1[t1_start]) # текущая разность времени\n",
    "        while np.abs(timestamps2[max(0, cam2_frame-1)] - timestamps1[t1_start]) < delta: # если дельта уменьшается при предыдущем кадре, то переходим на него (условие — строго меньше, так как времена всех кадров уникальны)\n",
    "            cam2_frame -= 1 # переходим на предыдущий кадр (без max, так как при нуле мы бы сюда не зашли в цикл)\n",
    "            delta = np.abs(timestamps2[cam2_frame] - timestamps1[t1_start]) # обновляем текущее значение delta\n",
    "        # после этого цикла мы либо находимся на оптимальном соответствии первого кадра первой камеры с кадром со второй камеры, либо оптимум — далее по времени (но не раньше!)\n",
    "\n",
    "        t1_current = t1_start # текущий кадр\n",
    "        for _, frame_time in enumerate(timestamps1[t1_start:t1_end]): # идём по кадрам (_ - номер кадра на первой камере, frame_time - время его запечатления)\n",
    "            delta = np.abs(timestamps2[cam2_frame] - frame_time) # текущая разность времени\n",
    "            while np.abs(timestamps2[min(cam2_frame+1, max_frame)] - frame_time) < delta: # если при переходе на следующий кадр дельта (разница времени) уменьшилась, то обновляем delta и соответствующий кадр на второй камере \n",
    "                cam2_frame += 1 # переходим на следующий кадр\n",
    "                delta = np.abs(timestamps2[cam2_frame] - frame_time)  # обновляем delta\n",
    "            correspondence[t1_current] = cam2_frame # если дельта перестала уменьшаеться — записываем найденный кадр с учётом сдвига от параллельного выполнения\n",
    "            t1_current += 1 # изменяем текущий кадр\n",
    "    return correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.3647298000000774\n",
      "1 0.6832738499999778\n",
      "2 0.45581383333334696\n",
      "3 0.3420914499999981\n",
      "4 0.2738818800000445\n"
     ]
    }
   ],
   "source": [
    "time_iterated_v2_parallel, answer_iterated_v2_parallel = calc_average_time(match_timestamps_iterated_v2_parallel, (timestamps1, timestamps2, cores_number), runs=runs) # подсчёт среднего времени (с njit и enumerate циклом)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(answer_iterated_v2_parallel==true_answer) # проверка, что функция отработала корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "- parallel iterated v2 ~ 0.2738 - 1.3647 секунд\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Лучшим вариантом, как и ожидалось, оказался итерационный алгоритм (njit + enumerate).\n",
    "* Циклы с enumerate показали себя лучше, чем циклы с np.arange.\n",
    "* Параллелизация может ускорить выполнение кода, однако её эффективность зависит от изначальной времени работы (возможен случай, что на распараллеливание уходит больше времени, чем на сам подсчёт).\n",
    "* njit ускоряет код вплоть x10, так как компилирует бинарные файлы для функций (без сигнатуры бинарный файл создастся при первом вызове, а не при определении функции), однако иногда он может наоборот — замедлить (см вариант 4 с параллельным запуском)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
